# Thesis 
=========================
# Herleitung & Problemstellung

# Herleitung

# Problemstellung

> Can the complexity of an everyday used files system be reduced and adapted to be used on a touchscreen without compromising the functionality and the user experience? Special attention shall be payed to the interface & workflow (system concept) which should be changed to account for gestural control.

Computer führt oft zu komplizierten Arbeitsabläufen und schafft Umwege durch Controller wie die Maus.
Der Computer hat viel neues Gebracht, aber viele gute Möglichkeiten der vorherigen Arbeitsweisen verdrängt.
-> zu Beispiel vereinen. 

- Touchscreen Geräte sind momentan sehr beschränkt in Bezug auf die von Ihnen gebotenen Möglichkeiten.

Haben Touchscreens & Gestensteuerung die Möglichkeit beide Arbeitsweisen zu vereinen?

Ziel ist es die Möglichkeiten des Computers mit der intuitiven und direkten Steuerung durch Gesten mithilfe eines Touchscreens zu vereinen, sodass alle Möglichkeiten einfach genutzt werden können und die Barriere der Steuerung verschwindet.
=========================
# Literaturrecherche & Projekte

## Gestures
**What is a gesture?**
A gesture can be a static postures or a dynamic movement. (10)   
A set of gestures designed for an interface is called "gestural vocabulary". (13)

**What is an intuitive gesture? define!**
An intuitive gestures must resemble the same or similar action in real life (e.g. Turning a page in a book and looking at the same picture) and in the controlled interface. If the action can not be performed in real life (e.g. pinch-to-zoom) it has to be learned and can therefore not be defined as intuitive. (7) Additionally the preference for gestures that do not resemble actions once would do in real life are highly individualized (10) which additionally contradicts the idea and goal to create intuitive gestures due to its unlikely success.

**Characteristics of a rememberable gesture**
Designing real intuitive gestures is nearly impossible, so I will discuss the next approach, tried by most companies manufacturing touch screen devices: *to design rememberable and usable gestures.*
If a gesture is differs enough from all others it is easier to remember than if the gestures are very similar. A gesture should have a uniqueness. The same idea of a gesture (like a swipe) should not be used in more than a couple gestures (e.g. 1 finger swipe, 2-finger swipe, 3-finger swipe) because this makes it harder to remember which action produces a specific result.

Gestures should be designed to full fill the following four criteria (13).
- Easy to perform and remember 
- Metaphorically and iconically logical towards functionality
- Ergonomic; not physically stressing when used often
- Possible for the system to recognise unambiguously

The main principles in ergonomics include (13): (*original sources in 13, needed?*)
- Avoid outer positions
- Relax muscles
- Relaxed neutral position is in the middle between outer positions
- Avoid repetition
- Avoid staying in static position
- Avoid internal and external force on joints that may stop body fluids

### Process for defining gestures (13)
1. Find the functions the interface has to have
2. Collect Gestures from User Domain (video testing)
3. Extract Gesture Vocabulary
4. (Benchmark chosen gestures - not doing this)

**FIND**
Cohen, C. (1999). A brief overview of gesture recognition. http://www.dai.ed.ac.uk/CVonline/local_copies/cohen/ges ture_overview.html

Another important factor, why for e.g. Apples gestures are so successful is that gestures have to feel right and be supporter by animations. Closing in application on the iPad can be done by placing 5 fingers spread out on the screen and pulling them together not unlike crumpling a piece of paper. The applications is minimised by scaling down to a size of 0. This supports the idea that you "crumple" the app, making the gesture feel right and helping to remember it, because you just remember to "crumple an app" to close.

Similar gestures should have similar results, so that the user is able to remember in clusters (**cluster reference**). (e.g. 1 finger swipe goes to next picture, 2-finger swipe goes to next gallery). Additionally opposite actions can use the exact opposite of a command like on Apple OS X where swipe up with 4 fingers shows all open windows while the swipe down with 4 fingers shows only the current application in focus.

As presented in the Magical number seven plus or minus two people have a hard time to remember many different items in combination with one specific topic if they do not use advanced memory techniques like chunks. Because one cannot expect users to use these techniques, the number of gestures essential for controlling an interface should not venture to far away from this number. The current version of Apple's OS facilitates 9 gesture clusters (7 single gestures and 2 clusters of 2 opposite gestures).

Additional research can provide an idea of common preferences for a specific group of people, though many factors like ethnic heritage, age, technological knowledge, personal preferences, left- or right-handed and many more will effect those preferences. **reference for this?**

The recognition accuracy by machines (11) has to be considered as well, due to its import ants to the user experience. Even intuitive gestures cannot create a good experience if they are not easily recognised. The accuracy of the machine understanding the users command has to be near perfect, so that the gestural interaction does not add an extra layer of complexity but rather reduces the amount of time and thought the user has to spend on controlling a device.

Gestures can be more tiresome (in contrast to using an input device such as a mouse), due to the movement and postures required. To reduce this as much as possible care must be taken to select gestures that avoid muscle strain and fatigue. (12) If such gestures must be used, the user should not be required to hold the gestures for an extended amount of time.

Fingers are less precise instruments than a mouse or pen is, leading to a greater chance of error or inadvertently touching/activating sth. this should be considered and the interface should be adjusted to wait for conformation (longer touch). Additionally the system should be forgiving meaning that errors are reversible (for e.g. deleted files can easily be restored, etc.).

**FIND**
> Stern, H. I., Wachs, J. P., & Edan, Y. (2006). Optimal hand gesture vocabulary design using psycho- physiological and technical factors. Proceedings of the Seventh International Conference on Automatic Face and Gesture Recognition (pp. 257-262).

> Kjeldsen, R., & Hartman J. (2001). Design issues for vision-based computer interaction systems. Proceedings of the Workshop on Perceptual User Interfaces, Orlando, Florida.

> *Gestures are similar* Aboudan, R., & Beattie, G. (1996). Cross-cultural similarities in gestures: The deep relationship between gestures and speech which transcends language barriers. Semiotica, no. 111, 269-294.

> *Gestures are individual* Archer, D. (1997). Unspoken diversity: cultural differences in gestures. Special Issue on Visual Sociology, Qualitative Sociology, 1, 3-137.

 - Studies of gestures?
- Apple Touch Gestures (as an example for gestures)
- Apple, google & Microsoft Patents for interactions 

**What benefits do gesture controlled interfaces have?**
- In contrast to button controlled Interfaces, some gestures (especially 3D gestures, but any gesture that does not need a specific point of focus (e.g. a swipe over the screen with no specific position)) are less likely to distract and create a complexity-overload (8).

- What kind of 3D gestures are possible?
- What problems arise from gestures in 3D space?
- How do people feel about using 3D gestures?
- Are there benefits of 3D gestures?

- S. Malassiotis, N. Aifanti, and M. Strintzis. A gesture
recognition system using 3D data. In Proceedings of 3D
Data Processing Visualization and Transmission
Symposium, pages 190{193, 2002.

- A. Riener, M. Rossbory, and A. Ferscha. Natural DVI
based on intuitive hand gestures. In Workshop UX in
Cars, Interact 2011, page 5, September 5th 2011.

> *Designing Intuitive Gesture-Based Human Interface Systems*
> Gestures have to be learned which lease to a barrier if to many gestures are required for operation (7)
	→ If gestures use "real life gestures" like "scrolling/	
		flipping" through a book, it is easier to remember.
→ My thought: One gesture has to do the same everywhere 
→ Apart from a few number of key gestures everything else should be accessible via UI (Pie Menues / half Pie Menus)

## GUI
### Characteristics of good gestural interfaces
There are 10 Characteristics suggested by (3) to consider when designing gestural interfaces.
**Discoverable**
**Trustworthy**
**Responsive**
**Appropriate**
**Meaningful**
**Smart**
**Clever**
**Playful**
**Pleasurable**
**Good**

- what gui elements work well with gesture operated touch screens?
- what gui elements do not work well with touch?
- what problems do touch gestures bring for the gui? (e.g. size of elements, hiding elements, ..)

## System structure
- which problems arise from common system structures when operated by touch screen devices? Solutions?
- which problems have systems due to their structure today?
- which solutions do user have?
- which solutions could be used for this problems? (Examples? Apple, Google)

## Touchscreen
### what advantages do touchscreens have. 
> multi-touch systems are capable of being adapted to almost any imaginable problem as the screen content can be modified to the developer's needs, he can simulate input devices such as keyboards or tasks like technical drawing by creating an adequate virtual reproduction. This makes touch screens a very flexible user interface system and enables extremely intuitiveapplications, if designed correctly. (1)

> Another specific positive aspect of multi-touch lies within the use of simultaneously handled input devices. As users can employ both their hands (and many fingers) or also different devices in combination with their hands at the same time, they are able to make signicant improvements regarding the time a task takes to be completed. Users need to be somewhat acquainted with the handling, but on simple and intuitive systems, this seems to be no problem, as Wu and Balakrishnan found out on assessing their Room Planner application (2).

> one can extract much information out of a single means of input, Finger touches can be varied in pressure sensitivity and angle (on several axes) and hands can be used to express a variety of gestures by tilting, flicking and catching or forming any conceivable kind of sign (2)

> multi-touch opens a whole new set of possibilities for applications since multi-touch implies not only multiple hands or devices but also multiple users. This enables the creation of reasonable collaborative touch systems, in which several users can interact with the screen as well as with each other simultaneously. (1)

### problems of touch screens? solutions?
> On the negative side, multi-touch systems complicate the occlusion problem, as several fingers, hands or devices are clouding even more parts of the touch screen than on singletouch devices. This can, however, be eased by using clever interface design approaches, as Wu and Balakrishnan confirmed (2). Another basic issue is the fat finger problem which requires designers to use interaction elements of a certain minimum size, in order to be precisely touchable by human fingers. (Which can be solved by having an invisible touchable overlay to the visual element, the so called ice berg tips (3))

> The surface of a multi-touch systems must always be in sight to get discernable display information (4). However, this is on some occasions hardly possible, like driving a car or operating a device within a pocket. It also restricts simple touch screens from being a beneficial device for visually impaired users (6). In some fields, a touch screen is mostly exposed to sunlight as with notebooks or mobile phones and visibility can be heavily a affected as well. Additionally hands cover part of the screen and thus potentially cover the interface. This must be considered and prevented as good as possible. (3)

> Feedback is not felt, but can only be given by sound or a visual effect on screen. Sound can be muted and a visual effect can be easily overlook, thus resulting in an insecurity of the user about wether or not an action has taken effect. A solution can be a tactile feedback using a touchscreen such as developed by tactus. (5)

> Additionally a team at Stanford developed a Solution for creating a keyboard for blind people on-the-go. By just placing your outstretched hands on the screen it registers the positions and creates the touchable areas. (15) 

> What is more, some actions like scribbling notes or making finer drawings cannot be reasonably performed with fingers and on small screens (4). You need a device of a certain size or one that explicitly can handle appropriate input tools such as a stylus additionally to the usual hand and finger recognition. (This can be solved by pens similar to drawing tables as are sold for the iPad *find source*)

> Also, even though touch screens can adapt very closely to a vast number of application purposes, they will only ever be a virtual representation of the original situation and lack certain features such as a plastic shape. This can make a significant difference in the handling of the interface, as can be seen when trying to rapidly handle a virtual keyboard in contrast to the real thing. (1) (This problem is being address by multiple companies like Tactus (5) by creating programmatically transformable touch surfaces)

## Optimizing Workspace
- How does a efficient/intuitive workspace look like?
- what is a productive work environment?

→ go more towards collaboration? And modern ideas of company hirachie? 

## Other Research
*usability engineering follows nine heuristics* (14)
1. Use simple and natural dialogue
2. Speak the user’s language
3. Minimize user memory load
4. Be consistent
5. Provide feedback
6. Provide clearly marked exits
7. Provide shortcuts
8. Provide good error messages
9. Prevent errors


=========================
# Die Evolution des Arbeitsplatzes
=========================
# Konzept
- Interaktion & Design
=========================
# Diskussion
- Blinde Nutzer
- Kulturelle & Persönliche Unterschiede (understanding gestures)
=========================
# Fazit & Ausblick

# Literature list
(1) A Short Report on Multi-Touch User Interfaces Patrick Lindemann Department Media Informatics, University of Munich Amalienstrasse 17 Munich, Germany patrick.lindemann@campus.lmu.de

(2) M. Wu and R. Balakrishnan. Multinger and whole hand gestural interaction techniques for multi-user tabletop displays. In UIST '03: Proceedings of the 16th annual ACM symposium on User interface software and technology, pages 193{202, New York, NY, USA, 2003. ACM.

(3) Designing Gestural Interfaces. Saffer, Dan (2008): Designing Gestural Interfaces. O’reilly: Sebastopol.

(4) B. Buxton. Multi-touch systems that I have known and loved. http://billbuxton.com/multitouchOverview.html, 2009.

(5) Taking Touch Screen Interfaces Into A New Dimension - A TACTUS TECHNOLOGY WHITE PAPER. 2012 Tactus Technology, Inc.

(6) Investigating Touchscreen Accessibility for People with Visual Impairments. David McGookin, Stephen Brewster, WeiWei Jiang Department of Computing Science. University of Glasgow
Glasgow, G12 8QQ

(7) Designing Intuitive Gesture-Based Human Interface Systems - Silicon Labs

(8) Natural and Intuitive Hand Gestures: A Substitute for Traditional Vehicle Control? A. Riener and M. Rossbory. Institute for Pervasive Computing, Johannes Kepler University, Linz/Austria

(9) G. A. Miller. The Magical Number Seven, Plus or
Minus Two: Some Limits on Our Capacity for
Processing Information. The Psychological Review, 1956. Online, www.musanim.com/miller1956.

(10) Optimal Consensus Intuitive Hand Gesture Vocabulary Design - Helman I Stern1, Juan P. Wachs2, and Yael Edan1
1Depart. of Industrial Engineering and Management, Ben-Gurion University of the Negev, Beersheva, Israel, {helman, yael}@bgu.ac.il
2Depart. of Computer Science, Naval Postgraduate School, Monterey, CA, jpwachs@nps.edu

(11) Wachs, J. P., Stern, H., & Edan, Y. (2005). Cluster labeling and parameter estimation for automated set up of a hand gesture recognition system. IEEE Transactions on Systems, Man and Cybernetics, Part A, 35(6), 932-944.

(12) Wachs, J. P. (2007). Ph.D. Thesis, Department of Industrial Engineering and Management, Ben-Gurion University of the Negev, Beersheva, Israel.

(13) A procedure for developing intuitive and ergonomic gesture interfaces for HCI. Michael Nielsen, Moritz Störring, Thomas B. Moeslund, and Erik Granum
{mnielsen, mst, tbm, eg}@cvmt.dk
Aalborg University, Laboratory of Computer Vision and Media Technology, Niels Jernes Vej 14, DK-9220 Aalborg, Denmark

(14) Jakob Nielsen, “The Usability Engineering Life Cycle”, IEEE, 1992

(15) Laboratory Equipment - A Touchscreen for the Blind. Stanford